# OLIR Chatbot â€“ RAG-Based PDF Question Answering System

OLIR Chatbot is a document-aware AI assistant built using Retrieval-Augmented Generation (RAG). Users can upload PDF documents and chat with an AI that responds based on the uploaded content. The system includes a modern React-based frontend and a powerful FastAPI backend, featuring semantic search, GPT-based reasoning, and persistent chat history.

## ğŸ“Œ Features

- ğŸ“ Upload and process PDF documents  
- ğŸ§  Ask questions and get GPT answers based on your documents  
- ğŸ” Semantic search using FAISS + SentenceTransformers  
- ğŸ’¬ Interactive chat interface with session history  
- ğŸ“š Document summaries and smart chunking  
- ğŸ“¤ Export chat sessions (planned: TXT, Markdown, JSON)  
- âš™ï¸ Modern tech stack: React + FastAPI + OpenRouter + FAISS  

## ğŸ–¼ï¸ System Architecture

### ğŸ”§ Backend

- FastAPI (Python)  
- PyPDF2 â€“ PDF text extraction  
- SentenceTransformers â€“ `all-MiniLM-L6-v2` for embeddings  
- FAISS â€“ Vector similarity search  
- OpenRouter API â€“ LLM integration (GPT-4o-mini)  
- Uvicorn â€“ ASGI server  
- Chat history, summaries, and vectors stored locally  

### ğŸŒ Frontend

- React 18 (Vite-based)  
- TailwindCSS for styling  
- React Router for navigation  
- Axios for API calls  
## Images

![img alt](https://github.com/santhosheyzz/Olir-Chatbot/blob/7c964627f9a8e6464789ec5c8b37d386f9aaf548/Documentation/loading%20screen.png)
![img alt](https://github.com/santhosheyzz/Olir-Chatbot/blob/7c964627f9a8e6464789ec5c8b37d386f9aaf548/Documentation/1.png)
![img alt](https://github.com/santhosheyzz/Olir-Chatbot/blob/7c964627f9a8e6464789ec5c8b37d386f9aaf548/Documentation/2.png)
![img alt](https://github.com/santhosheyzz/Olir-Chatbot/blob/7c964627f9a8e6464789ec5c8b37d386f9aaf548/Documentation/3.png)
![img alt](https://github.com/santhosheyzz/Olir-Chatbot/blob/7c964627f9a8e6464789ec5c8b37d386f9aaf548/Documentation/4.png)

## ğŸ“‚ Project Structure

```
bash
olir-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ user_docs/
â”‚   â”‚   â”œâ”€â”€ faiss_index/
â”‚   â”‚   â””â”€â”€ chat_history/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ components/

```

## ğŸš€ Getting Started

### ğŸ›  Backend Setup

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

### ğŸ’» Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

## ğŸ“ˆ Future Enhancements

* ğŸ—‚ Multi-document querying
* ğŸ” User authentication and profiles
* ğŸ“Š Filter/search by content in Document Library
* ğŸ”„ Shareable chat sessions
* ğŸ“± Mobile app version
* ï¿½ YouTube transcript integration

## ğŸ§  How It Works (RAG Flow)

1. **Upload PDF** â†’ Text is extracted, chunked, embedded
2. **Ask a Question** â†’ Your question is embedded
3. **Search FAISS** â†’ Most relevant chunks are retrieved
4. **LLM (GPT-4o)** â†’ Generates a response grounded only in the retrieved content
5. **Chat Saved** â†’ Session is logged for future reference

## ğŸ‘¨â€ğŸ’» Contributors

* Santhoshkumar T
* Sivaguru R
* Dilip Kumar S

## ğŸ“… Project Timeline

* Initial build: June 2025
* Report completed: July 2025
* Deployment & enhancement: In Progress...

## ğŸ“œ License

MIT License

> ğŸ’¡ Feel free to fork, star â­, and contribute to make this even better!
